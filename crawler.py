import requests
from bs4 import BeautifulSoup

def crawl():
    # ì‹¤ì œ ê²€ìƒ‰ ë°ì´í„°ê°€ ë‹´ê¸°ëŠ” URLì…ë‹ˆë‹¤.
    url = "https://www.work24.go.kr/wk/wan/empSrch/retriveWorkNeEmpSrchList.do"
    
    # ğŸ•µï¸ ë” ì •êµí•œ ì‚¬ëŒ í‰ë‚´ (Headers ë³´ê°•)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Referer": "https://www.work24.go.kr/"
    }
    
    try:
        res = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ê³ ìš©24ì˜ í˜„ì¬ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì„ íƒìë¥¼ ë³´ê°•í–ˆìŠµë‹ˆë‹¤.
        jobs = soup.select(".table-wrap tbody tr")
        
        results = []
        for job in jobs:
            title_tag = job.select_one(".subject a")
            if title_tag:
                title = title_tag.text.strip()
                # ğŸ”— í˜•ë‹˜ì´ ê·¸í† ë¡ ì›í•˜ì‹œë˜ 'ì§„ì§œ ìƒì„¸ ë§í¬' ì£¼ì†Œ
                link = "https://www.work24.go.kr" + title_tag['href']
                results.append(f"ì œëª©: {title} | ë§í¬: {link}")
        
        # ë§Œì•½ ì•„ë¬´ê²ƒë„ ëª» ê¸ì—ˆë‹¤ë©´ ì—ëŸ¬ í™•ì¸ìš© ë©”ì‹œì§€ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
        if not results:
            results.append("ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ ì ê²€ ì¤‘ì´ê±°ë‚˜ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        with open("job_list.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(results))
        print("âœ… ìˆ˜ì§‘ ì„±ê³µ!")
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    crawl()
